import pandas as pd
import requests
from urllib import parse
from requests.exceptions import ConnectionError, TooManyRedirects, ReadTimeout, MissingSchema
from datetime import time


def load_data(csv_in: str) -> pd.DataFrame:
    df_all_data = pd.read_csv(csv_in, header=0)
    df_url = df_all_data['clickable_url'].to_frame()
    print(type(df_url))

    return df_url


def get_urls(df_in: pd.DataFrame) -> list:
    urls_list = []
    for url in df_in['clickable_url']:
        urls_list.append(url)

    return urls_list


def get_hostname_from_url(url: str) -> str:
    """Returns hostname from a url e.g pure.qub.ac.uk

    Args:
        url (str): url to break down

    Returns:
        str: hostname
    """
    try:
        hostname = parse.urlsplit(url).hostname
    except AttributeError:
        hostname = "error"
    return hostname


def check_url(url: str):
    hostname = get_hostname_from_url(url)
    headers = {
        # "Host": hostname,
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "en-GB,en;q=0.5",
        "Referer": 'https://www.google.com/',
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "same-origin",
    }

    try:
        r = requests.get(url, headers=headers, timeout=10)
        print(url, r.status_code)
        return r.status_code

    except ConnectionError:
        return "ConnectionError"
    except TooManyRedirects:
        return "TooManyRedirectsError"
    except ReadTimeout:
        return "ReadTimeoutError"
    except MissingSchema:
        return "MissingSchema"


def check(df):
    urls = get_urls(df)
    for url in urls:
        print(check_url(url))


def main():
    df = load_data(csv_in='all_data_manual_software.csv')
    df['url_check'] = df['clickable_url'].apply(check_url)
    print(df)
    df.to_csv('urlcheck.csv')

    # todo:
    # check for missing schema http/s


main()
